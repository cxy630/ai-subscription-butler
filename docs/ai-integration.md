# AIé›†æˆæ–‡æ¡£ - OpenAI API é›†æˆæŒ‡å—

## æ¦‚è¿°

AIè®¢é˜…ç®¡å®¶é›†æˆäº†OpenAI GPTæ¨¡å‹ï¼Œä¸ºç”¨æˆ·æä¾›æ™ºèƒ½å¯¹è¯å’Œæ•°æ®åˆ†æåŠŸèƒ½ã€‚æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»äº†AIé›†æˆçš„æ¶æ„ã€é…ç½®æ–¹æ³•ã€ä½¿ç”¨æŒ‡å—å’Œæœ€ä½³å®è·µã€‚

## åŠŸèƒ½ç‰¹æ€§

### ğŸ¤– æ ¸å¿ƒAIåŠŸèƒ½
- **æ™ºèƒ½å¯¹è¯**: åŸºäºç”¨æˆ·è®¢é˜…æ•°æ®çš„ä¸ªæ€§åŒ–AIåŠ©æ‰‹
- **æ™ºèƒ½æ´å¯Ÿ**: è‡ªåŠ¨åˆ†æè®¢é˜…æ¨¡å¼ï¼Œç”Ÿæˆä¼˜åŒ–å»ºè®®
- **ä¸Šä¸‹æ–‡è®°å¿†**: ç»´æŠ¤å¯¹è¯å†å²ï¼Œæä¾›è¿è´¯çš„äº¤äº’ä½“éªŒ
- **å¤šè¯­è¨€æ”¯æŒ**: ä¸»è¦æ”¯æŒä¸­æ–‡ï¼Œå¯æ‰©å±•å…¶ä»–è¯­è¨€

### ğŸ›¡ï¸ å¯é æ€§ä¿éšœ
- **æ™ºèƒ½é™çº§**: OpenAI APIä¸å¯ç”¨æ—¶è‡ªåŠ¨åˆ‡æ¢åˆ°æ¨¡æ‹Ÿå“åº”
- **é”™è¯¯å¤„ç†**: å®Œå–„çš„å¼‚å¸¸å¤„ç†å’Œç”¨æˆ·å‹å¥½çš„é”™è¯¯æç¤º
- **é€Ÿç‡é™åˆ¶**: å†…ç½®è¯·æ±‚é¢‘ç‡æ§åˆ¶ï¼Œé˜²æ­¢APIé¢åº¦æ»¥ç”¨
- **é…ç½®çµæ´»**: æ”¯æŒå®Œå…¨æ— APIå¯†é’¥è¿è¡Œ

## æ¶æ„è®¾è®¡

### æ¨¡å—ç»“æ„
```
core/ai/
â”œâ”€â”€ __init__.py          # æ¨¡å—å¯¼å‡ºå’Œå…¬å…±æ¥å£
â”œâ”€â”€ config.py           # AIé…ç½®ç®¡ç†
â”œâ”€â”€ openai_client.py    # OpenAI APIå®¢æˆ·ç«¯
â””â”€â”€ assistant.py        # AIåŠ©æ‰‹æœåŠ¡
```

### ç»„ä»¶å…³ç³»å›¾
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   UIç»„ä»¶        â”‚â”€â”€â”€â”€â”‚   AIåŠ©æ‰‹æœåŠ¡     â”‚â”€â”€â”€â”€â”‚  OpenAIå®¢æˆ·ç«¯   â”‚
â”‚ (chat.py/home.py)â”‚    â”‚  (assistant.py)  â”‚    â”‚(openai_client.py)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
         â”‚              â”‚   é…ç½®ç®¡ç†       â”‚             â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚   (config.py)    â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ•°æ®æµç¨‹
1. **ç”¨æˆ·è¾“å…¥** â†’ UIç»„ä»¶æ¥æ”¶ç”¨æˆ·æ¶ˆæ¯
2. **ä¸Šä¸‹æ–‡æ„å»º** â†’ æ•´åˆç”¨æˆ·æ•°æ®å’Œå¯¹è¯å†å²
3. **AIè°ƒç”¨** â†’ é€šè¿‡åŠ©æ‰‹æœåŠ¡è°ƒç”¨OpenAI API
4. **å“åº”å¤„ç†** â†’ è§£æAIå›å¤ï¼Œæå–æ„å›¾å’Œç½®ä¿¡åº¦
5. **é™çº§æœºåˆ¶** â†’ APIå¤±è´¥æ—¶ä½¿ç”¨æ¨¡æ‹Ÿå“åº”
6. **ç»“æœå±•ç¤º** â†’ åœ¨UIä¸­æ˜¾ç¤ºAIå“åº”å’Œç›¸å…³ä¿¡æ¯

## é…ç½®æŒ‡å—

### ç¯å¢ƒå˜é‡é…ç½®

#### åŸºæœ¬é…ç½®
```bash
# OpenAI APIå¯†é’¥ (å¿…éœ€)
OPENAI_API_KEY=sk-your-openai-api-key-here

# æ¨¡å‹é€‰æ‹© (å¯é€‰ï¼Œé»˜è®¤gpt-3.5-turbo)
OPENAI_MODEL=gpt-3.5-turbo

# APIå‚æ•° (å¯é€‰)
OPENAI_MAX_TOKENS=1000
OPENAI_TEMPERATURE=0.7
```

#### é«˜çº§é…ç½®
```bash
# AIåŠ©æ‰‹é…ç½®
AI_MAX_HISTORY=10                    # å¯¹è¯å†å²ä¿ç•™æ¡æ•°
AI_DEFAULT_LANGUAGE=zh-CN           # é»˜è®¤è¯­è¨€
AI_RESPONSE_TIMEOUT=30              # å“åº”è¶…æ—¶æ—¶é—´(ç§’)
AI_MAX_DAILY_REQUESTS=1000          # æ¯æ—¥è¯·æ±‚é™åˆ¶

# åŠŸèƒ½å¼€å…³
AI_ENABLE_INSIGHTS=true             # å¯ç”¨æ™ºèƒ½æ´å¯Ÿç”Ÿæˆ
AI_ENABLE_MEMORY=true               # å¯ç”¨å¯¹è¯è®°å¿†
AI_ENABLE_FALLBACK=true             # å¯ç”¨é™çº§å“åº”
AI_CONTENT_FILTER=true              # å¯ç”¨å†…å®¹è¿‡æ»¤
```

### é…ç½®æ–¹æ³•

#### æ–¹æ³•1: ä½¿ç”¨é…ç½®å‘å¯¼ (æ¨è)
```bash
python scripts/setup_ai.py
```
é…ç½®å‘å¯¼æä¾›äº¤äº’å¼ç•Œé¢ï¼Œå¸®åŠ©ç”¨æˆ·ï¼š
- æ£€æŸ¥å½“å‰é…ç½®çŠ¶æ€
- åˆ›å»ºå’Œæ›´æ–°.envæ–‡ä»¶
- éªŒè¯APIå¯†é’¥æ ¼å¼
- æµ‹è¯•APIè¿æ¥

#### æ–¹æ³•2: æ‰‹åŠ¨é…ç½®
```bash
# 1. å¤åˆ¶ç¯å¢ƒé…ç½®æ¨¡æ¿
cp .env.example .env

# 2. ç¼–è¾‘.envæ–‡ä»¶
nano .env

# 3. é‡å¯åº”ç”¨
python run_app.py
```

#### æ–¹æ³•3: ä»£ç ä¸­é…ç½®
```python
from core.ai import update_ai_config

update_ai_config(
    openai_api_key="your-api-key",
    openai_model="gpt-3.5-turbo",
    max_daily_requests=500
)
```

## ä½¿ç”¨æŒ‡å—

### åŸºæœ¬ç”¨æ³•

#### æ£€æŸ¥AIçŠ¶æ€
```python
from core.ai import is_ai_assistant_available, get_ai_assistant

# æ£€æŸ¥AIæ˜¯å¦å¯ç”¨
if is_ai_assistant_available():
    print("AIåŠ©æ‰‹åœ¨çº¿")
else:
    print("AIåŠ©æ‰‹ç¦»çº¿ï¼Œä½¿ç”¨æ¨¡æ‹Ÿå“åº”")

# è·å–çŠ¶æ€è¯¦æƒ…
assistant = get_ai_assistant()
status = assistant.get_status()
print(f"æ¨¡å‹: {status['model']}")
print(f"ä»Šæ—¥ä½¿ç”¨: {status['daily_requests_used']}/{status['daily_limit']}")
```

#### æ™ºèƒ½å¯¹è¯
```python
from core.ai import chat_with_ai_sync

user_context = {
    "monthly_spending": 150.0,
    "subscriptions": [
        {"service_name": "Netflix", "price": 15.99, "category": "entertainment"},
        {"service_name": "Spotify", "price": 9.99, "category": "entertainment"}
    ],
    "subscription_categories": {
        "entertainment": {"count": 2, "spending": 25.98}
    }
}

response = chat_with_ai_sync(
    user_message="æˆ‘æ¯æœˆåœ¨å¨±ä¹ä¸ŠèŠ±å¤šå°‘é’±ï¼Ÿ",
    user_context=user_context
)

print(f"AIå›å¤: {response['response']}")
print(f"ç½®ä¿¡åº¦: {response['confidence']}")
print(f"æ„å›¾: {response['intent']}")
```

#### ç”Ÿæˆæ™ºèƒ½æ´å¯Ÿ
```python
import asyncio
from core.ai import generate_ai_insights

async def get_insights():
    insights = await generate_ai_insights(user_context)
    for insight in insights:
        print(f"{insight['icon']} {insight['title']}")
        print(f"   {insight['content']}")

# åœ¨å¼‚æ­¥ç¯å¢ƒä¸­è°ƒç”¨
asyncio.run(get_insights())

# æˆ–åœ¨Streamlitä¸­åŒæ­¥è°ƒç”¨
assistant = get_ai_assistant()
insights = asyncio.run(assistant.generate_insights(user_context))
```

### é«˜çº§ç”¨æ³•

#### è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯
```python
from core.ai import OpenAIClient

client = OpenAIClient()
client.system_prompt = """
ä½ æ˜¯ä¸“ä¸šçš„è´¢åŠ¡é¡¾é—®ï¼Œä¸“é—¨å¸®åŠ©ç”¨æˆ·ä¼˜åŒ–è®¢é˜…æ”¯å‡ºã€‚
è¯·ç”¨ç®€æ´ä¸“ä¸šçš„è¯­è¨€æä¾›å»ºè®®ã€‚
"""
```

#### å¼‚æ­¥æ‰¹é‡å¤„ç†
```python
import asyncio
from core.ai import get_ai_assistant

async def batch_analyze(user_messages, user_context):
    assistant = get_ai_assistant()
    tasks = [
        assistant.chat(msg, user_context)
        for msg in user_messages
    ]
    responses = await asyncio.gather(*tasks)
    return responses
```

## APIæ¥å£æ–‡æ¡£

### AIConfigç±»
é…ç½®ç®¡ç†ç±»ï¼Œè´Ÿè´£AIç›¸å…³å‚æ•°çš„å­˜å‚¨å’ŒéªŒè¯ã€‚

```python
@dataclass
class AIConfig:
    openai_api_key: Optional[str] = None
    openai_model: str = "gpt-3.5-turbo"
    openai_max_tokens: int = 1000
    openai_temperature: float = 0.7
    max_conversation_history: int = 10
    # ... æ›´å¤šé…ç½®é¡¹
```

**ä¸»è¦æ–¹æ³•:**
- `from_env()`: ä»ç¯å¢ƒå˜é‡åˆ›å»ºé…ç½®
- `to_dict()`: è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
- `is_valid()`: éªŒè¯é…ç½®æœ‰æ•ˆæ€§

### OpenAIClientç±»
OpenAI APIå®¢æˆ·ç«¯ï¼Œå¤„ç†ä¸OpenAIæœåŠ¡çš„ç›´æ¥äº¤äº’ã€‚

```python
class OpenAIClient:
    def __init__(self, api_key: Optional[str] = None)

    async def get_ai_response(
        self,
        user_message: str,
        user_context: Dict[str, Any],
        conversation_history: Optional[List[Dict]] = None
    ) -> Dict[str, Any]

    def get_ai_response_sync(...) -> Dict[str, Any]

    async def generate_insights(
        self,
        user_context: Dict[str, Any]
    ) -> List[Dict[str, str]]
```

### AIAssistantç±»
AIåŠ©æ‰‹æœåŠ¡ï¼Œæä¾›é«˜çº§AIåŠŸèƒ½å’Œç®¡ç†ã€‚

```python
class AIAssistant:
    def __init__(self, config: Optional[AIConfig] = None)

    def is_available() -> bool

    async def chat(
        self,
        user_message: str,
        user_context: Dict[str, Any],
        conversation_history: Optional[List[Dict]] = None
    ) -> Dict[str, Any]

    def chat_sync(...) -> Dict[str, Any]

    async def generate_insights(
        self,
        user_context: Dict[str, Any]
    ) -> List[Dict[str, str]]

    def get_status() -> Dict[str, Any]
```

## é™çº§æœºåˆ¶

### æ™ºèƒ½é™çº§ç­–ç•¥
å½“OpenAI APIä¸å¯ç”¨æ—¶ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨å¯ç”¨é™çº§æœºåˆ¶ï¼š

1. **APIæ£€æŸ¥**: å¯åŠ¨æ—¶æ£€æŸ¥APIå¯†é’¥å’Œè¿æ¥çŠ¶æ€
2. **å®æ—¶ç›‘æ§**: è¿è¡Œæ—¶ç›‘æ§APIå“åº”çŠ¶æ€
3. **è‡ªåŠ¨åˆ‡æ¢**: APIå¤±è´¥æ—¶ç«‹å³åˆ‡æ¢åˆ°æ¨¡æ‹Ÿå“åº”
4. **ç”¨æˆ·æç¤º**: åœ¨UIä¸­æ˜ç¡®æ˜¾ç¤ºå½“å‰ä½¿ç”¨çš„å“åº”æ¨¡å¼

### æ¨¡æ‹Ÿå“åº”å®ç°
```python
def get_ai_response_mock(user_message: str, user_context: dict) -> str:
    """åŸºäºè§„åˆ™çš„æ™ºèƒ½æ¨¡æ‹Ÿå“åº”"""
    message_lower = user_message.lower()

    # æ”¯å‡ºæŸ¥è¯¢
    if any(word in message_lower for word in ["èŠ±è´¹", "æ”¯å‡º", "é’±"]):
        monthly_spending = user_context.get("monthly_spending", 0)
        return f"æ‚¨çš„æ€»æœˆåº¦è®¢é˜…æ”¯å‡ºä¸º Â¥{monthly_spending:.2f}"

    # è®¢é˜…æ•°é‡æŸ¥è¯¢
    elif any(word in message_lower for word in ["å¤šå°‘", "å‡ ä¸ª", "æ•°é‡"]):
        subscriptions = user_context.get("subscriptions", [])
        return f"æ‚¨ç›®å‰æœ‰ {len(subscriptions)} ä¸ªæ´»è·ƒè®¢é˜…"

    # é»˜è®¤å“åº”
    else:
        return "æ‚¨å¥½ï¼æˆ‘æ˜¯æ‚¨çš„AIè®¢é˜…ç®¡å®¶åŠ©æ‰‹..."
```

### é™çº§è´¨é‡ä¿è¯
- **æ™ºèƒ½è§„åˆ™**: åŸºäºå…³é”®è¯åŒ¹é…å’Œæ¨¡å¼è¯†åˆ«
- **ä¸Šä¸‹æ–‡æ„ŸçŸ¥**: åˆ©ç”¨ç”¨æˆ·æ•°æ®ç”Ÿæˆä¸ªæ€§åŒ–å“åº”
- **ä¸€è‡´æ€§**: ä¿æŒä¸çœŸå®AIå“åº”ç›¸ä¼¼çš„æ ¼å¼å’Œé£æ ¼
- **å®Œæ•´æ€§**: è¦†ç›–ä¸»è¦ä½¿ç”¨åœºæ™¯å’ŒæŸ¥è¯¢ç±»å‹

## æ€§èƒ½ä¼˜åŒ–

### è¯·æ±‚ä¼˜åŒ–
```python
# 1. ä½¿ç”¨è¿æ¥æ± 
import openai
openai.api_requestor._make_session = lambda: requests.Session()

# 2. è®¾ç½®åˆç†çš„è¶…æ—¶æ—¶é—´
response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=messages,
    timeout=30  # 30ç§’è¶…æ—¶
)

# 3. æ‰¹é‡å¤„ç†
tasks = [client.get_ai_response(msg, context) for msg in messages]
responses = await asyncio.gather(*tasks, return_exceptions=True)
```

### ç¼“å­˜ç­–ç•¥
```python
import functools
from datetime import datetime, timedelta

@functools.lru_cache(maxsize=100)
def get_cached_insights(user_id: str, data_hash: str):
    """ç¼“å­˜ç”¨æˆ·æ´å¯Ÿï¼Œé¿å…é‡å¤è®¡ç®—"""
    # å®ç°ç¼“å­˜é€»è¾‘
    pass
```

### å†…å­˜ç®¡ç†
```python
# é™åˆ¶å¯¹è¯å†å²é•¿åº¦
conversation_history = conversation_history[-10:]  # åªä¿ç•™æœ€è¿‘10æ¡

# æ¸…ç†å¤§å¯¹è±¡
del large_response_data
import gc
gc.collect()
```

## é”™è¯¯å¤„ç†

### å¼‚å¸¸ç±»å‹å’Œå¤„ç†ç­–ç•¥

#### APIç›¸å…³é”™è¯¯
```python
try:
    response = await client.get_ai_response(message, context)
except openai.error.RateLimitError:
    # é€Ÿç‡é™åˆ¶é”™è¯¯
    return {"error": "è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åé‡è¯•"}
except openai.error.InvalidRequestError:
    # è¯·æ±‚å‚æ•°é”™è¯¯
    return {"error": "è¯·æ±‚æ ¼å¼é”™è¯¯"}
except openai.error.AuthenticationError:
    # è®¤è¯é”™è¯¯
    return {"error": "APIå¯†é’¥æ— æ•ˆ"}
except openai.error.OpenAIError as e:
    # é€šç”¨OpenAIé”™è¯¯
    return {"error": f"AIæœåŠ¡é”™è¯¯: {str(e)}"}
```

#### ç½‘ç»œå’Œè¶…æ—¶é”™è¯¯
```python
import requests
import asyncio

try:
    response = await asyncio.wait_for(
        client.get_ai_response(message, context),
        timeout=30.0
    )
except asyncio.TimeoutError:
    return {"error": "AIå“åº”è¶…æ—¶ï¼Œè¯·é‡è¯•"}
except requests.exceptions.ConnectionError:
    return {"error": "ç½‘ç»œè¿æ¥å¤±è´¥"}
```

### ç”¨æˆ·å‹å¥½çš„é”™è¯¯æç¤º
```python
ERROR_MESSAGES = {
    "rate_limit": "ğŸ˜… AIåŠ©æ‰‹å¤ªå¿™äº†ï¼Œè¯·ç¨åé‡è¯•",
    "auth_error": "ğŸ”‘ APIå¯†é’¥é…ç½®æœ‰è¯¯ï¼Œè¯·æ£€æŸ¥è®¾ç½®",
    "network_error": "ğŸŒ ç½‘ç»œè¿æ¥ä¸ç¨³å®šï¼Œè¯·æ£€æŸ¥ç½‘ç»œ",
    "timeout": "â±ï¸ AIæ€è€ƒæ—¶é—´å¤ªé•¿ï¼Œè¯·é‡è¯•",
    "unknown": "ğŸ¤– AIåŠ©æ‰‹æš‚æ—¶ä¸å¯ç”¨ï¼Œå·²åˆ‡æ¢åˆ°æ™ºèƒ½æ¨¡æ‹Ÿæ¨¡å¼"
}
```

## å®‰å…¨è€ƒè™‘

### APIå¯†é’¥å®‰å…¨
- **ç¯å¢ƒå˜é‡**: å§‹ç»ˆä½¿ç”¨ç¯å¢ƒå˜é‡å­˜å‚¨APIå¯†é’¥
- **æƒé™æ§åˆ¶**: ä½¿ç”¨æœ€å°æƒé™åŸåˆ™é…ç½®APIå¯†é’¥
- **å®šæœŸè½®æ¢**: å®šæœŸæ›´æ–°APIå¯†é’¥
- **ç›‘æ§ä½¿ç”¨**: ç›‘æ§APIä½¿ç”¨æƒ…å†µï¼Œæ£€æµ‹å¼‚å¸¸æ´»åŠ¨

```python
# âŒ é”™è¯¯åšæ³•ï¼šç¡¬ç¼–ç å¯†é’¥
openai.api_key = "sk-hardcoded-key"

# âœ… æ­£ç¡®åšæ³•ï¼šç¯å¢ƒå˜é‡
openai.api_key = os.getenv("OPENAI_API_KEY")
```

### æ•°æ®éšç§
- **æ•°æ®æœ€å°åŒ–**: åªå‘é€å¿…è¦çš„ç”¨æˆ·æ•°æ®
- **åŒ¿ååŒ–**: ç§»é™¤æˆ–æ¨¡ç³ŠåŒ–æ•æ„Ÿä¿¡æ¯
- **æœ¬åœ°å¤„ç†**: ä¼˜å…ˆåœ¨æœ¬åœ°å¤„ç†æ•æ„Ÿæ•°æ®

```python
def sanitize_user_data(user_context):
    """æ¸…ç†ç”¨æˆ·æ•°æ®ï¼Œç§»é™¤æ•æ„Ÿä¿¡æ¯"""
    sanitized = user_context.copy()

    # ç§»é™¤ä¸ªäººèº«ä»½ä¿¡æ¯
    sanitized.pop("email", None)
    sanitized.pop("phone", None)
    sanitized.pop("address", None)

    # æ¨¡ç³ŠåŒ–æœåŠ¡åç§°
    if "subscriptions" in sanitized:
        for sub in sanitized["subscriptions"]:
            if "payment_method" in sub:
                del sub["payment_method"]

    return sanitized
```

### å†…å®¹å®‰å…¨
- **è¾“å…¥éªŒè¯**: éªŒè¯å’Œæ¸…ç†ç”¨æˆ·è¾“å…¥
- **è¾“å‡ºè¿‡æ»¤**: è¿‡æ»¤ä¸å½“å†…å®¹å’Œæ•æ„Ÿä¿¡æ¯
- **å®¡è®¡æ—¥å¿—**: è®°å½•é‡è¦æ“ä½œå’Œå¼‚å¸¸äº‹ä»¶

```python
import re

def validate_user_input(message: str) -> bool:
    """éªŒè¯ç”¨æˆ·è¾“å…¥å®‰å…¨æ€§"""
    # æ£€æŸ¥é•¿åº¦é™åˆ¶
    if len(message) > 1000:
        return False

    # æ£€æŸ¥æ¶æ„æ¨¡å¼
    malicious_patterns = [
        r"<script",
        r"javascript:",
        r"eval\(",
        r"system\(",
    ]

    for pattern in malicious_patterns:
        if re.search(pattern, message, re.IGNORECASE):
            return False

    return True
```

## ç›‘æ§å’Œæ—¥å¿—

### æ—¥å¿—é…ç½®
```python
import logging
import structlog

# ç»“æ„åŒ–æ—¥å¿—é…ç½®
logging.basicConfig(
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
    level=logging.INFO
)

logger = structlog.get_logger(__name__)

# AIæ“ä½œæ—¥å¿—
def log_ai_interaction(user_id, message, response, tokens_used):
    logger.info(
        "ai_interaction",
        user_id=user_id,
        message_length=len(message),
        response_length=len(response),
        tokens_used=tokens_used,
        model="gpt-3.5-turbo"
    )
```

### æ€§èƒ½ç›‘æ§
```python
import time
from functools import wraps

def monitor_ai_performance(func):
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = await func(*args, **kwargs)
            success = True
        except Exception as e:
            result = None
            success = False
            logger.error("ai_call_failed", error=str(e))
            raise
        finally:
            duration = time.time() - start_time
            logger.info(
                "ai_performance",
                function=func.__name__,
                duration=duration,
                success=success
            )
        return result
    return wrapper
```

### ä½¿ç”¨ç»Ÿè®¡
```python
class AIUsageTracker:
    def __init__(self):
        self.daily_requests = 0
        self.total_tokens = 0
        self.error_count = 0

    def track_request(self, tokens_used: int):
        self.daily_requests += 1
        self.total_tokens += tokens_used

    def track_error(self, error_type: str):
        self.error_count += 1
        logger.warning("ai_error_tracked", error_type=error_type)

    def get_stats(self) -> dict:
        return {
            "daily_requests": self.daily_requests,
            "total_tokens": self.total_tokens,
            "error_count": self.error_count,
            "error_rate": self.error_count / max(self.daily_requests, 1)
        }
```

## æµ‹è¯•æŒ‡å—

### å•å…ƒæµ‹è¯•
```python
import pytest
from unittest.mock import Mock, patch
from core.ai import AIAssistant, AIConfig

class TestAIAssistant:
    @pytest.fixture
    def ai_config(self):
        return AIConfig(
            openai_api_key="test-key",
            openai_model="gpt-3.5-turbo"
        )

    @pytest.fixture
    def assistant(self, ai_config):
        return AIAssistant(ai_config)

    def test_is_available_with_valid_config(self, assistant):
        assert assistant.is_available()

    @patch('core.ai.openai_client.openai.ChatCompletion.create')
    async def test_chat_success(self, mock_create, assistant):
        # Mock OpenAIå“åº”
        mock_response = Mock()
        mock_response.choices[0].message.content = "Test response"
        mock_response.usage.total_tokens = 50
        mock_create.return_value = mock_response

        result = await assistant.chat(
            "Test message",
            {"monthly_spending": 100}
        )

        assert result["response"] == "Test response"
        assert result["tokens_used"] == 50
```

### é›†æˆæµ‹è¯•
```python
import pytest
import os
from core.ai import get_ai_assistant, is_ai_assistant_available

class TestAIIntegration:
    @pytest.mark.skipif(
        not os.getenv("OPENAI_API_KEY"),
        reason="éœ€è¦OpenAI APIå¯†é’¥"
    )
    async def test_real_api_call(self):
        assistant = get_ai_assistant()
        response = await assistant.chat(
            "æµ‹è¯•æ¶ˆæ¯",
            {"monthly_spending": 150, "subscriptions": []}
        )

        assert "response" in response
        assert response["confidence"] > 0
        assert response["tokens_used"] > 0

    def test_fallback_mechanism(self):
        # æµ‹è¯•APIä¸å¯ç”¨æ—¶çš„é™çº§æœºåˆ¶
        with patch.dict(os.environ, {"OPENAI_API_KEY": ""}, clear=False):
            assert not is_ai_assistant_available()

            assistant = get_ai_assistant()
            response = assistant.chat_sync(
                "æµ‹è¯•æ¶ˆæ¯",
                {"monthly_spending": 150}
            )

            assert response["model"] == "fallback"
            assert "response" in response
```

### è´Ÿè½½æµ‹è¯•
```python
import asyncio
import time
from concurrent.futures import ThreadPoolExecutor

async def load_test_ai_assistant():
    """è´Ÿè½½æµ‹è¯•AIåŠ©æ‰‹å¹¶å‘æ€§èƒ½"""
    assistant = get_ai_assistant()

    async def single_request():
        start_time = time.time()
        response = await assistant.chat(
            "æµ‹è¯•æ¶ˆæ¯",
            {"monthly_spending": 100}
        )
        duration = time.time() - start_time
        return duration, response

    # å¹¶å‘10ä¸ªè¯·æ±‚
    tasks = [single_request() for _ in range(10)]
    results = await asyncio.gather(*tasks, return_exceptions=True)

    # åˆ†æç»“æœ
    durations = [r[0] for r in results if not isinstance(r, Exception)]
    errors = [r for r in results if isinstance(r, Exception)]

    print(f"æˆåŠŸè¯·æ±‚: {len(durations)}")
    print(f"å¤±è´¥è¯·æ±‚: {len(errors)}")
    print(f"å¹³å‡å“åº”æ—¶é—´: {sum(durations)/len(durations):.2f}ç§’")
    print(f"æœ€å¤§å“åº”æ—¶é—´: {max(durations):.2f}ç§’")
```

## å¸¸è§é—®é¢˜è§£ç­”

### Q: å¦‚ä½•è·å–OpenAI APIå¯†é’¥ï¼Ÿ
A:
1. è®¿é—® [OpenAIå¹³å°](https://platform.openai.com/api-keys)
2. ç™»å½•æˆ–æ³¨å†Œè´¦æˆ·
3. ç‚¹å‡» "Create new secret key"
4. å¤åˆ¶ç”Ÿæˆçš„APIå¯†é’¥
5. è®¾ç½®ç¯å¢ƒå˜é‡æˆ–ä½¿ç”¨é…ç½®å‘å¯¼

### Q: ä¸é…ç½®APIå¯†é’¥èƒ½ä½¿ç”¨AIåŠŸèƒ½å—ï¼Ÿ
A: å¯ä»¥ï¼ç³»ç»Ÿä¼šè‡ªåŠ¨ä½¿ç”¨æ™ºèƒ½æ¨¡æ‹Ÿå“åº”ï¼Œè™½ç„¶åŠŸèƒ½æœ‰é™ä½†èƒ½æ»¡è¶³åŸºæœ¬éœ€æ±‚ã€‚çœŸå®APIæä¾›æ›´å‡†ç¡®å’Œä¸ªæ€§åŒ–çš„å“åº”ã€‚

### Q: å¦‚ä½•æ§åˆ¶APIä½¿ç”¨æˆæœ¬ï¼Ÿ
A:
- è®¾ç½®æ¯æ—¥è¯·æ±‚é™åˆ¶ (`AI_MAX_DAILY_REQUESTS`)
- å‡å°‘æœ€å¤§ä»¤ç‰Œæ•° (`OPENAI_MAX_TOKENS`)
- ä¼˜åŒ–æç¤ºè¯é•¿åº¦
- ä½¿ç”¨ç¼“å­˜æœºåˆ¶
- ç›‘æ§ä½¿ç”¨ç»Ÿè®¡

### Q: APIè¯·æ±‚å¤±è´¥æ€ä¹ˆåŠï¼Ÿ
A: ç³»ç»Ÿæœ‰å®Œå–„çš„é”™è¯¯å¤„ç†æœºåˆ¶ï¼š
- è‡ªåŠ¨é‡è¯•æœºåˆ¶
- æ™ºèƒ½é™çº§åˆ°æ¨¡æ‹Ÿå“åº”
- ç”¨æˆ·å‹å¥½çš„é”™è¯¯æç¤º
- è¯¦ç»†çš„é”™è¯¯æ—¥å¿—è®°å½•

### Q: å¦‚ä½•è‡ªå®šä¹‰AIå“åº”é£æ ¼ï¼Ÿ
A: ä¿®æ”¹ç³»ç»Ÿæç¤ºè¯æˆ–è°ƒæ•´æ¨¡å‹å‚æ•°ï¼š
```python
from core.ai import update_ai_config

update_ai_config(
    openai_temperature=0.3,  # æ›´ä¿å®ˆçš„å“åº”
    # æˆ–åœ¨ä»£ç ä¸­ä¿®æ”¹ system_prompt
)
```

### Q: æ”¯æŒå“ªäº›OpenAIæ¨¡å‹ï¼Ÿ
A: é»˜è®¤ä½¿ç”¨ `gpt-3.5-turbo`ï¼Œæ”¯æŒé…ç½®ï¼š
- `gpt-3.5-turbo` (æ¨èï¼Œæˆæœ¬æ•ˆç›Šå¥½)
- `gpt-4` (æ›´æ™ºèƒ½ä½†æˆæœ¬é«˜)
- `gpt-4-turbo-preview` (æœ€æ–°åŠŸèƒ½)

## æ•…éšœæ’é™¤

### å¸¸è§é”™è¯¯å’Œè§£å†³æ–¹æ¡ˆ

#### 1. APIå¯†é’¥æ— æ•ˆ
```
Error: openai.error.AuthenticationError
```
**è§£å†³æ–¹æ¡ˆ:**
- æ£€æŸ¥APIå¯†é’¥æ ¼å¼ (åº”ä»¥ `sk-` å¼€å¤´)
- éªŒè¯APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆ
- ç¡®è®¤è´¦æˆ·æœ‰è¶³å¤Ÿä½™é¢
- æ£€æŸ¥ç¯å¢ƒå˜é‡è®¾ç½®

#### 2. é€Ÿç‡é™åˆ¶
```
Error: openai.error.RateLimitError
```
**è§£å†³æ–¹æ¡ˆ:**
- ç­‰å¾…ä¸€æ®µæ—¶é—´åé‡è¯•
- å‡å°‘è¯·æ±‚é¢‘ç‡
- å‡çº§APIè®¡åˆ’
- å®ç°è¯·æ±‚é˜Ÿåˆ—

#### 3. ç½‘ç»œè¿æ¥é—®é¢˜
```
Error: requests.exceptions.ConnectionError
```
**è§£å†³æ–¹æ¡ˆ:**
- æ£€æŸ¥ç½‘ç»œè¿æ¥
- é…ç½®ä»£ç†è®¾ç½®
- å¢åŠ è¶…æ—¶æ—¶é—´
- ä½¿ç”¨é‡è¯•æœºåˆ¶

#### 4. æ¨¡å—å¯¼å…¥é”™è¯¯
```
ImportError: No module named 'openai'
```
**è§£å†³æ–¹æ¡ˆ:**
```bash
pip install openai
# æˆ–
pip install -r requirements.txt
```

### è°ƒè¯•æŠ€å·§

#### å¯ç”¨è¯¦ç»†æ—¥å¿—
```python
import logging
logging.getLogger("core.ai").setLevel(logging.DEBUG)
```

#### æµ‹è¯•APIè¿æ¥
```python
from core.ai import get_openai_client

client = get_openai_client()
if client:
    print("âœ… OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
else:
    print("âŒ OpenAIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥")
```

#### æ£€æŸ¥é…ç½®
```python
from core.ai import get_ai_config, is_ai_configured

config = get_ai_config()
print(f"é…ç½®æœ‰æ•ˆ: {is_ai_configured()}")
print(f"é…ç½®è¯¦æƒ…: {config.to_dict()}")
```

## æ›´æ–°å†å²

### v1.0.0 (2024-09)
- âœ… åˆå§‹AIé›†æˆå®ç°
- âœ… OpenAI GPT-3.5-turboæ”¯æŒ
- âœ… æ™ºèƒ½é™çº§æœºåˆ¶
- âœ… é…ç½®ç®¡ç†ç³»ç»Ÿ
- âœ… åŸºç¡€é”™è¯¯å¤„ç†

### æœªæ¥è®¡åˆ’
- ğŸ”® æ”¯æŒæ›´å¤šAIæ¨¡å‹ (Claude, Gemini)
- ğŸ”® è¯­éŸ³äº¤äº’åŠŸèƒ½
- ğŸ”® å¤šè¯­è¨€æ”¯æŒæ‰©å±•
- ğŸ”® é«˜çº§ç¼“å­˜ç­–ç•¥
- ğŸ”® AIè®­ç»ƒæ•°æ®ä¼˜åŒ–

---

*å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·è®¿é—® [GitHub Issues](https://github.com/cxy630/ai-subscription-butler/issues)*