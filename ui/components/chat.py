"""
AIèŠå¤©ç•Œé¢ç»„ä»¶ - ä¸AIåŠ©æ‰‹å¯¹è¯
"""

import streamlit as st
from datetime import datetime
import sys
from pathlib import Path
import asyncio

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from core.database.data_interface import data_manager
from core.ai import get_ai_assistant, is_ai_assistant_available

def get_ai_response_mock(user_message: str, user_context: dict) -> str:
    """
    æ¨¡æ‹ŸAIå“åº” - åœ¨æ²¡æœ‰OpenAI APIçš„æƒ…å†µä¸‹æä¾›æ™ºèƒ½å“åº”

    Args:
        user_message: ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯
        user_context: ç”¨æˆ·ä¸Šä¸‹æ–‡ä¿¡æ¯

    Returns:
        AIå“åº”å­—ç¬¦ä¸²
    """
    message_lower = user_message.lower()

    # è·å–ç”¨æˆ·æ•°æ®ç”¨äºæ™ºèƒ½å“åº”
    subscriptions = user_context.get("subscriptions", [])
    monthly_spending = user_context.get("monthly_spending", 0)
    categories = user_context.get("subscription_categories", {})

    # æ”¯å‡ºç›¸å…³æŸ¥è¯¢
    if any(word in message_lower for word in ["èŠ±è´¹", "æ”¯å‡º", "é’±", "è´¹ç”¨", "æˆæœ¬"]):
        if "å¨±ä¹" in message_lower or "entertainment" in message_lower:
            entertainment_cost = categories.get("entertainment", {}).get("spending", 0)
            return f"ğŸ¬ æ‚¨åœ¨å¨±ä¹ç±»è®¢é˜…ä¸Šçš„æœˆåº¦æ”¯å‡ºä¸º Â¥{entertainment_cost:.2f}ï¼ŒåŒ…æ‹¬è§†é¢‘ã€éŸ³ä¹ç­‰æœåŠ¡ã€‚å»ºè®®å®šæœŸè¯„ä¼°ä½¿ç”¨é¢‘ç‡ï¼Œå–æ¶ˆä¸å¸¸ç”¨çš„æœåŠ¡ã€‚"

        elif "ç”Ÿäº§åŠ›" in message_lower or "productivity" in message_lower:
            productivity_cost = categories.get("productivity", {}).get("spending", 0)
            return f"âš¡ æ‚¨åœ¨ç”Ÿäº§åŠ›å·¥å…·ä¸Šçš„æœˆåº¦æ”¯å‡ºä¸º Â¥{productivity_cost:.2f}ã€‚è¿™ç±»æŠ•èµ„é€šå¸¸èƒ½æé«˜å·¥ä½œæ•ˆç‡ï¼Œä½†å»ºè®®é¿å…åŠŸèƒ½é‡å çš„å·¥å…·ã€‚"

        else:
            return f"ğŸ’° æ‚¨çš„æ€»æœˆåº¦è®¢é˜…æ”¯å‡ºä¸º Â¥{monthly_spending:.2f}ï¼Œå¹´åº¦æ”¯å‡ºçº¦ Â¥{monthly_spending * 12:.2f}ã€‚å…¶ä¸­åŒ…å« {len(subscriptions)} ä¸ªæ´»è·ƒè®¢é˜…ï¼Œæ¶µç›– {len(categories)} ä¸ªä¸åŒç±»åˆ«ã€‚"

    # è®¢é˜…æ•°é‡æŸ¥è¯¢
    elif any(word in message_lower for word in ["å¤šå°‘", "å‡ ä¸ª", "æ•°é‡", "è®¢é˜…"]):
        return f"ğŸ“Š æ‚¨ç›®å‰æœ‰ {len(subscriptions)} ä¸ªæ´»è·ƒè®¢é˜…ã€‚åˆ†ç±»æƒ…å†µï¼š" + \
               "".join([f"\nâ€¢ {cat}: {stats['count']}ä¸ªæœåŠ¡" for cat, stats in categories.items()])

    # å–æ¶ˆè®¢é˜…ç›¸å…³
    elif any(word in message_lower for word in ["å–æ¶ˆ", "åœæ­¢", "åˆ é™¤"]):
        if subscriptions:
            most_expensive = max(subscriptions, key=lambda x: x.get("price", 0))
            unused_suggestions = [s for s in subscriptions if s.get("category") == "entertainment"]

            response = "ğŸ¤” å…³äºå–æ¶ˆè®¢é˜…çš„å»ºè®®ï¼š\n"
            response += f"â€¢ æœ€è´µçš„è®¢é˜…æ˜¯ {most_expensive['service_name']} (Â¥{most_expensive['price']}/æœˆ)\n"
            if unused_suggestions:
                response += f"â€¢ å¯ä»¥è€ƒè™‘æš‚åœä¸å¸¸ç”¨çš„å¨±ä¹æœåŠ¡\n"
            response += "â€¢ å»ºè®®å…ˆæš‚åœè€Œä¸æ˜¯ç›´æ¥å–æ¶ˆï¼Œè§‚å¯Ÿä¸€æ®µæ—¶é—´åå†å†³å®š"
            return response
        else:
            return "æ‚¨ç›®å‰æ²¡æœ‰æ´»è·ƒçš„è®¢é˜…éœ€è¦å–æ¶ˆã€‚"

    # èŠ‚çœå»ºè®®
    elif any(word in message_lower for word in ["èŠ‚çœ", "çœé’±", "ä¼˜åŒ–", "å»ºè®®"]):
        suggestions = []

        if monthly_spending > 200:
            suggestions.append("ğŸ’¡ æ‚¨çš„æœˆåº¦è®¢é˜…æ”¯å‡ºè¾ƒé«˜ï¼Œå»ºè®®å®šæœŸè¯„ä¼°å„æœåŠ¡çš„ä½¿ç”¨é¢‘ç‡")

        if len(categories) > 1:
            entertainment_cost = categories.get("entertainment", {}).get("spending", 0)
            if entertainment_cost > 50:
                suggestions.append("ğŸ¬ å¨±ä¹ç±»è®¢é˜…æ”¯å‡ºè¾ƒå¤šï¼Œå¯ä»¥è€ƒè™‘é€‰æ‹©æ€§ä¿ç•™æœ€å¸¸ç”¨çš„æœåŠ¡")

        # æŸ¥æ‰¾å¯èƒ½çš„é‡å¤æœåŠ¡
        service_names = [s.get("service_name", "") for s in subscriptions]
        if any("spotify" in s.lower() and "apple music" in " ".join(service_names).lower() for s in service_names):
            suggestions.append("ğŸµ æ£€æµ‹åˆ°å¤šä¸ªéŸ³ä¹æœåŠ¡ï¼Œå»ºè®®åªä¿ç•™ä¸€ä¸ª")

        if not suggestions:
            suggestions.append("âœ… æ‚¨çš„è®¢é˜…ç»“æ„æ¯”è¾ƒåˆç†ï¼Œç»§ç»­ä¿æŒå®šæœŸè¯„ä¼°çš„ä¹ æƒ¯")

        return "ğŸ’¡ ä¸ªæ€§åŒ–èŠ‚çœå»ºè®®ï¼š\n" + "\n".join(suggestions)

    # æ·»åŠ è®¢é˜…
    elif any(word in message_lower for word in ["æ·»åŠ ", "æ–°å¢", "è®¢é˜…"]):
        return "â• æ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼æ·»åŠ è®¢é˜…ï¼š\nâ€¢ ç‚¹å‡»ä¾§è¾¹æ çš„'æ·»åŠ è®¢é˜…'æŒ‰é’®\nâ€¢ ä½¿ç”¨'æ‰«æè´¦å•'åŠŸèƒ½è‡ªåŠ¨è¯†åˆ«\nâ€¢ å‘Šè¯‰æˆ‘å…·ä½“çš„æœåŠ¡åç§°å’Œä»·æ ¼ï¼Œæˆ‘æ¥å¸®æ‚¨æ·»åŠ "

    # é»˜è®¤å“åº”
    else:
        return f"ğŸ¤– æ‚¨å¥½ï¼æˆ‘æ˜¯æ‚¨çš„AIè®¢é˜…ç®¡å®¶åŠ©æ‰‹ã€‚\n\n" \
               f"ğŸ“Š æ‚¨ç›®å‰çš„çŠ¶å†µï¼š\n" \
               f"â€¢ æ´»è·ƒè®¢é˜…ï¼š{len(subscriptions)} ä¸ª\n" \
               f"â€¢ æœˆåº¦æ”¯å‡ºï¼šÂ¥{monthly_spending:.2f}\n" \
               f"â€¢ æœåŠ¡ç±»åˆ«ï¼š{len(categories)} ä¸ª\n\n" \
               f"ğŸ’¡ æˆ‘å¯ä»¥å¸®æ‚¨ï¼š\n" \
               f"â€¢ åˆ†æè®¢é˜…æ”¯å‡ºå’Œä½¿ç”¨æƒ…å†µ\n" \
               f"â€¢ æä¾›èŠ‚çœå’Œä¼˜åŒ–å»ºè®®\n" \
               f"â€¢ ç®¡ç†è®¢é˜…çš„æ·»åŠ å’Œå–æ¶ˆ\n" \
               f"â€¢ å›ç­”ä»»ä½•å…³äºè®¢é˜…çš„é—®é¢˜\n\n" \
               f"è¯·å‘Šè¯‰æˆ‘æ‚¨æƒ³äº†è§£ä»€ä¹ˆï¼Ÿ"

def render_chat_message(message: dict, is_user: bool = True):
    """æ¸²æŸ“å•ä¸ªèŠå¤©æ¶ˆæ¯"""
    if is_user:
        with st.chat_message("user", avatar="ğŸ‘¤"):
            st.write(message.get("message", message.get("content", "")))
    else:
        with st.chat_message("assistant", avatar="ğŸ¤–"):
            response = message.get("response", message.get("content", ""))
            st.write(response)

            # æ˜¾ç¤ºç½®ä¿¡åº¦ï¼ˆå¦‚æœæœ‰ï¼‰
            confidence = message.get("confidence")
            if confidence:
                st.caption(f"ç½®ä¿¡åº¦: {confidence:.2%}")

def render_chat_history():
    """æ¸²æŸ“èŠå¤©å†å²"""
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    # æ˜¾ç¤ºå†å²æ¶ˆæ¯
    for i, message_pair in enumerate(st.session_state.chat_history):
        if isinstance(message_pair, dict):
            # å•ä¸ªæ¶ˆæ¯
            is_user = message_pair.get("role") == "user"
            render_chat_message(message_pair, is_user)
        elif isinstance(message_pair, tuple):
            # æ¶ˆæ¯å¯¹
            user_msg, ai_msg = message_pair
            render_chat_message({"content": user_msg}, True)
            render_chat_message({"content": ai_msg}, False)

def render_suggested_questions():
    """æ¸²æŸ“å»ºè®®é—®é¢˜"""
    st.subheader("ğŸ’¡ è¯•è¯•é—®æˆ‘è¿™äº›é—®é¢˜ï¼š")

    suggestions = [
        "æˆ‘æ¯æœˆåœ¨å¨±ä¹ä¸ŠèŠ±å¤šå°‘é’±ï¼Ÿ",
        "æœ‰ä»€ä¹ˆèŠ‚çœå»ºè®®å—ï¼Ÿ",
        "æˆ‘æœ‰å‡ ä¸ªè®¢é˜…æœåŠ¡ï¼Ÿ",
        "æœ€è´µçš„è®¢é˜…æ˜¯ä»€ä¹ˆï¼Ÿ",
        "å“ªäº›æœåŠ¡å¯ä»¥å–æ¶ˆï¼Ÿ",
        "æˆ‘çš„è®¢é˜…ç»“æ„åˆç†å—ï¼Ÿ"
    ]

    cols = st.columns(2)
    for i, suggestion in enumerate(suggestions):
        with cols[i % 2]:
            if st.button(f"ğŸ’­ {suggestion}", key=f"suggestion_{i}", use_container_width=True):
                # å°†å»ºè®®é—®é¢˜æ·»åŠ åˆ°è¾“å…¥æ¡†
                st.session_state.user_input = suggestion
                st.rerun()

def get_ai_response_smart(user_message: str, user_context: dict) -> dict:
    """
    æ™ºèƒ½AIå“åº” - ä¼˜å…ˆä½¿ç”¨OpenAI APIï¼Œå¤±è´¥æ—¶ä½¿ç”¨æ¨¡æ‹Ÿå“åº”

    Args:
        user_message: ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯
        user_context: ç”¨æˆ·ä¸Šä¸‹æ–‡ä¿¡æ¯

    Returns:
        AIå“åº”ç»“æœå­—å…¸
    """
    # æ£€æŸ¥AIåŠ©æ‰‹æ˜¯å¦å¯ç”¨
    if is_ai_assistant_available():
        try:
            ai_assistant = get_ai_assistant()

            # è·å–å¯¹è¯å†å²
            conversation_history = []
            if "chat_history" in st.session_state:
                for i, (user_msg, ai_msg) in enumerate(st.session_state.chat_history):
                    if user_msg:  # è·³è¿‡æ¬¢è¿æ¶ˆæ¯
                        conversation_history.append({"role": "user", "content": user_msg})
                        if isinstance(ai_msg, str):
                            conversation_history.append({"role": "assistant", "content": ai_msg})
                        elif isinstance(ai_msg, dict):
                            conversation_history.append({"role": "assistant", "content": ai_msg.get("response", "")})

            # è°ƒç”¨AIåŠ©æ‰‹
            response = ai_assistant.chat_sync(user_message, user_context, conversation_history)
            return response

        except Exception as e:
            st.error(f"AIåŠ©æ‰‹è°ƒç”¨å¤±è´¥: {str(e)}")
            # é™çº§åˆ°æ¨¡æ‹Ÿå“åº”

    # ä½¿ç”¨æ¨¡æ‹Ÿå“åº”ä½œä¸ºé™çº§
    mock_response = get_ai_response_mock(user_message, user_context)
    return {
        "response": mock_response,
        "intent": "fallback",
        "confidence": 0.6,
        "model": "fallback",
        "timestamp": datetime.now().isoformat()
    }

def render_ai_status():
    """æ¸²æŸ“AIçŠ¶æ€ä¿¡æ¯"""
    if is_ai_assistant_available():
        ai_assistant = get_ai_assistant()
        status = ai_assistant.get_status()

        col1, col2 = st.columns(2)
        with col1:
            st.success(f"ğŸ¤– AIåŠ©æ‰‹: åœ¨çº¿ ({status['model']})")
        with col2:
            requests_used = status['daily_requests_used']
            daily_limit = status['daily_limit']
            st.info(f"ğŸ“Š ä»Šæ—¥ä½¿ç”¨: {requests_used}/{daily_limit}")
    else:
        st.warning("ğŸ¤– AIåŠ©æ‰‹: ç¦»çº¿ (ä½¿ç”¨æ¨¡æ‹Ÿå“åº”)")

def render_chat_interface():
    """æ¸²æŸ“å®Œæ•´çš„èŠå¤©ç•Œé¢"""
    st.title("ğŸ¤– AIåŠ©æ‰‹")

    if not st.session_state.current_user_id:
        st.warning("è¯·å…ˆé€‰æ‹©ç”¨æˆ·")
        return

    # æ˜¾ç¤ºAIçŠ¶æ€
    render_ai_status()
    st.divider()

    # è·å–ç”¨æˆ·ä¸Šä¸‹æ–‡
    user_context = data_manager.get_user_overview(st.session_state.current_user_id) or {}

    # èŠå¤©å®¹å™¨
    chat_container = st.container()

    with chat_container:
        # æ˜¾ç¤ºæ¬¢è¿æ¶ˆæ¯
        if "chat_initialized" not in st.session_state:
            st.session_state.chat_initialized = True
            # ä½¿ç”¨æ™ºèƒ½å“åº”ç”Ÿæˆæ¬¢è¿æ¶ˆæ¯
            welcome_response = get_ai_response_smart("ä½ å¥½", user_context)
            welcome_msg = welcome_response["response"] if isinstance(welcome_response, dict) else welcome_response
            st.session_state.chat_history = [(None, welcome_msg)]

        # æ˜¾ç¤ºèŠå¤©å†å²
        render_chat_history()

    # è¾“å…¥åŒºåŸŸ
    st.divider()

    # ç”¨æˆ·è¾“å…¥
    user_input = st.text_input(
        "ğŸ’¬ å‘AIåŠ©æ‰‹æé—®ï¼š",
        placeholder="ä¾‹å¦‚ï¼šæˆ‘æ¯æœˆåœ¨å¨±ä¹ä¸ŠèŠ±å¤šå°‘é’±ï¼Ÿ",
        key="user_input_field",
        value=st.session_state.get("user_input", "")
    )

    col1, col2, col3, col4 = st.columns([2, 1, 1, 1])

    with col1:
        send_button = st.button("ğŸ“¤ å‘é€", use_container_width=True, type="primary")

    with col2:
        if st.button("ğŸ—‘ï¸ æ¸…ç©º", use_container_width=True):
            st.session_state.chat_history = []
            st.session_state.user_input = ""
            st.session_state.chat_initialized = False
            st.rerun()

    with col3:
        if st.button("ğŸ’¡ å»ºè®®", use_container_width=True):
            st.session_state.show_suggestions = not st.session_state.get("show_suggestions", False)
            st.rerun()

    with col4:
        if st.button("âš™ï¸ è®¾ç½®", use_container_width=True):
            st.session_state.show_chat_settings = not st.session_state.get("show_chat_settings", False)
            st.rerun()

    # å¤„ç†ç”¨æˆ·è¾“å…¥
    if send_button and user_input.strip():
        # æ˜¾ç¤ºå¤„ç†çŠ¶æ€
        with st.spinner("ğŸ¤– AIåŠ©æ‰‹æ­£åœ¨æ€è€ƒ..."):
            # è·å–AIå“åº”
            ai_response_data = get_ai_response_smart(user_input, user_context)

            # æå–å“åº”æ–‡æœ¬
            if isinstance(ai_response_data, dict):
                ai_response = ai_response_data["response"]
                intent = ai_response_data.get("intent", "general_query")
                confidence = ai_response_data.get("confidence", 0.8)
            else:
                ai_response = ai_response_data
                intent = "general_query"
                confidence = 0.8

            # ä¿å­˜å¯¹è¯åˆ°å†å²
            st.session_state.chat_history.append((user_input, ai_response_data))

            # ä¿å­˜åˆ°æ•°æ®åº“
            data_manager.save_conversation(
                user_id=st.session_state.current_user_id,
                session_id=st.session_state.chat_session_id,
                message=user_input,
                response=ai_response,
                intent=intent,
                confidence=confidence
            )

            # æ¸…ç©ºè¾“å…¥
            st.session_state.user_input = ""
            st.rerun()

    # æ¸…ç©ºä¸´æ—¶è¾“å…¥çŠ¶æ€
    if "user_input" in st.session_state:
        del st.session_state.user_input

    # æ˜¾ç¤ºå»ºè®®é—®é¢˜
    if st.session_state.get("show_suggestions", False):
        st.divider()
        render_suggested_questions()

    # æ˜¾ç¤ºèŠå¤©è®¾ç½®
    if st.session_state.get("show_chat_settings", False):
        st.divider()
        render_chat_settings()

    # èŠå¤©ç»Ÿè®¡
    st.divider()

    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ğŸ’¬ å¯¹è¯è½®æ•°", len(st.session_state.get("chat_history", [])))

    with col2:
        # è·å–æ•°æ®åº“ä¸­çš„å†å²å¯¹è¯æ•°
        session_history = data_manager.get_session_history(st.session_state.chat_session_id)
        st.metric("ğŸ“œ å†å²è®°å½•", len(session_history))

    with col3:
        st.metric("ğŸ¯ ä¼šè¯ID", st.session_state.chat_session_id[:8] + "...")

    with col4:
        # æ˜¾ç¤ºAIæ¨¡å‹ä¿¡æ¯
        if is_ai_assistant_available():
            ai_assistant = get_ai_assistant()
            status = ai_assistant.get_status()
            st.metric("ğŸ§  AIæ¨¡å‹", status["model"])
        else:
            st.metric("ğŸ§  AIæ¨¡å‹", "æ¨¡æ‹Ÿå“åº”")

def render_chat_settings():
    """æ¸²æŸ“èŠå¤©è®¾ç½®"""
    with st.expander("âš™ï¸ èŠå¤©è®¾ç½®"):
        st.subheader("AIåŠ©æ‰‹é…ç½®")

        # å“åº”é£æ ¼
        response_style = st.selectbox(
            "å“åº”é£æ ¼",
            ["friendly", "professional", "concise"],
            format_func=lambda x: {"friendly": "å‹å¥½", "professional": "ä¸“ä¸š", "concise": "ç®€æ´"}[x]
        )

        # è¯¦ç»†ç¨‹åº¦
        detail_level = st.slider("å“åº”è¯¦ç»†ç¨‹åº¦", 1, 5, 3)

        # æ˜¯å¦åŒ…å«å»ºè®®
        include_suggestions = st.checkbox("åŒ…å«ä¼˜åŒ–å»ºè®®", value=True)

        if st.button("ğŸ’¾ ä¿å­˜è®¾ç½®"):
            st.session_state.chat_settings = {
                "response_style": response_style,
                "detail_level": detail_level,
                "include_suggestions": include_suggestions
            }
            st.success("è®¾ç½®å·²ä¿å­˜")

if __name__ == "__main__":
    # æµ‹è¯•ç»„ä»¶
    render_chat_interface()