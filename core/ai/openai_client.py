"""
OpenAI APIå®¢æˆ·ç«¯ - å¤„ç†ä¸OpenAIæœåŠ¡çš„äº¤äº’
"""

import openai
import json
from typing import Dict, List, Optional, Any
from datetime import datetime
import os
from pathlib import Path

class OpenAIClient:
    """OpenAI APIå®¢æˆ·ç«¯ç±»"""

    def __init__(self, api_key: Optional[str] = None):
        """
        åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯

        Args:
            api_key: OpenAI APIå¯†é’¥ï¼Œå¦‚æœä¸ºNoneåˆ™ä»ç¯å¢ƒå˜é‡è¯»å–
        """
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError("æœªæ‰¾åˆ°OpenAI APIå¯†é’¥ï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡OPENAI_API_KEYæˆ–ä¼ å…¥api_keyå‚æ•°")

        # é…ç½®OpenAIå®¢æˆ·ç«¯
        openai.api_key = self.api_key

        # ç³»ç»Ÿæç¤ºè¯
        self.system_prompt = """ä½ æ˜¯AIè®¢é˜…ç®¡å®¶çš„æ™ºèƒ½åŠ©æ‰‹ï¼Œä¸“é—¨å¸®åŠ©ç”¨æˆ·ç®¡ç†è®¢é˜…æœåŠ¡ã€‚

ä½ çš„èƒ½åŠ›åŒ…æ‹¬ï¼š
1. åˆ†æç”¨æˆ·çš„è®¢é˜…æ”¯å‡ºæƒ…å†µ
2. æä¾›ä¸ªæ€§åŒ–çš„èŠ‚çœå»ºè®®
3. å›ç­”å…³äºè®¢é˜…ç®¡ç†çš„é—®é¢˜
4. è¯†åˆ«é‡å¤æˆ–ä¸å¿…è¦çš„è®¢é˜…
5. é¢„æµ‹æ”¯å‡ºè¶‹åŠ¿

å›å¤è¦æ±‚ï¼š
- ä½¿ç”¨ä¸­æ–‡å›å¤
- è¯­è¨€äº²åˆ‡ã€ä¸“ä¸š
- æä¾›å…·ä½“çš„æ•°æ®åˆ†æ
- ç»™å‡ºå¯æ‰§è¡Œçš„å»ºè®®
- æ ¹æ®ç”¨æˆ·æ•°æ®ä¸ªæ€§åŒ–å“åº”

å½“ç”¨æˆ·è¯¢é—®æ—¶ï¼ŒåŸºäºæä¾›çš„ç”¨æˆ·æ•°æ®è¿›è¡Œåˆ†æå’Œå»ºè®®ã€‚"""

    async def get_ai_response(
        self,
        user_message: str,
        user_context: Dict[str, Any],
        conversation_history: Optional[List[Dict]] = None
    ) -> Dict[str, Any]:
        """
        è·å–AIåŠ©æ‰‹å“åº”

        Args:
            user_message: ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯
            user_context: ç”¨æˆ·ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆè®¢é˜…æ•°æ®ç­‰ï¼‰
            conversation_history: å¯¹è¯å†å²

        Returns:
            åŒ…å«AIå“åº”å’Œç›¸å…³ä¿¡æ¯çš„å­—å…¸
        """
        try:
            # æ„å»ºæ¶ˆæ¯ä¸Šä¸‹æ–‡
            context_info = self._build_context_string(user_context)

            # æ„å»ºå¯¹è¯æ¶ˆæ¯
            messages = [
                {"role": "system", "content": self.system_prompt},
                {"role": "system", "content": f"ç”¨æˆ·å½“å‰æ•°æ®ï¼š\n{context_info}"}
            ]

            # æ·»åŠ å¯¹è¯å†å²ï¼ˆæœ€è¿‘5è½®å¯¹è¯ï¼‰
            if conversation_history:
                recent_history = conversation_history[-10:]  # å–æœ€è¿‘10æ¡æ¶ˆæ¯
                for msg in recent_history:
                    if msg.get("role") in ["user", "assistant"]:
                        messages.append({
                            "role": msg["role"],
                            "content": msg["content"]
                        })

            # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
            messages.append({"role": "user", "content": user_message})

            # è°ƒç”¨OpenAI API
            response = await openai.ChatCompletion.acreate(
                model="gpt-3.5-turbo",
                messages=messages,
                max_tokens=1000,
                temperature=0.7,
                presence_penalty=0.1,
                frequency_penalty=0.1
            )

            # è§£æå“åº”
            ai_message = response.choices[0].message.content.strip()

            # åˆ†æå“åº”æ„å›¾å’Œç½®ä¿¡åº¦
            intent = self._analyze_intent(user_message)
            confidence = self._calculate_confidence(response, user_message)

            return {
                "response": ai_message,
                "intent": intent,
                "confidence": confidence,
                "tokens_used": response.usage.total_tokens,
                "model": "gpt-3.5-turbo",
                "timestamp": datetime.now().isoformat()
            }

        except Exception as e:
            # è¿”å›é”™è¯¯ä¿¡æ¯å’Œé™çº§å“åº”
            fallback_response = self._get_fallback_response(user_message, user_context)
            return {
                "response": fallback_response,
                "intent": "error_fallback",
                "confidence": 0.5,
                "error": str(e),
                "model": "fallback",
                "timestamp": datetime.now().isoformat()
            }

    def get_ai_response_sync(
        self,
        user_message: str,
        user_context: Dict[str, Any],
        conversation_history: Optional[List[Dict]] = None
    ) -> Dict[str, Any]:
        """
        åŒæ­¥ç‰ˆæœ¬çš„AIå“åº”è·å–
        """
        try:
            # æ„å»ºæ¶ˆæ¯ä¸Šä¸‹æ–‡
            context_info = self._build_context_string(user_context)

            # æ„å»ºå¯¹è¯æ¶ˆæ¯
            messages = [
                {"role": "system", "content": self.system_prompt},
                {"role": "system", "content": f"ç”¨æˆ·å½“å‰æ•°æ®ï¼š\n{context_info}"}
            ]

            # æ·»åŠ å¯¹è¯å†å²
            if conversation_history:
                recent_history = conversation_history[-10:]
                for msg in recent_history:
                    if msg.get("role") in ["user", "assistant"]:
                        messages.append({
                            "role": msg["role"],
                            "content": msg["content"]
                        })

            # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
            messages.append({"role": "user", "content": user_message})

            # è°ƒç”¨OpenAI API (åŒæ­¥ç‰ˆæœ¬)
            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=messages,
                max_tokens=1000,
                temperature=0.7,
                presence_penalty=0.1,
                frequency_penalty=0.1
            )

            # è§£æå“åº”
            ai_message = response.choices[0].message.content.strip()

            # åˆ†æå“åº”æ„å›¾å’Œç½®ä¿¡åº¦
            intent = self._analyze_intent(user_message)
            confidence = self._calculate_confidence(response, user_message)

            return {
                "response": ai_message,
                "intent": intent,
                "confidence": confidence,
                "tokens_used": response.usage.total_tokens,
                "model": "gpt-3.5-turbo",
                "timestamp": datetime.now().isoformat()
            }

        except Exception as e:
            # è¿”å›é™çº§å“åº”
            fallback_response = self._get_fallback_response(user_message, user_context)
            return {
                "response": fallback_response,
                "intent": "error_fallback",
                "confidence": 0.5,
                "error": str(e),
                "model": "fallback",
                "timestamp": datetime.now().isoformat()
            }

    def _build_context_string(self, user_context: Dict[str, Any]) -> str:
        """æ„å»ºç”¨æˆ·ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²"""
        context_parts = []

        # åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
        if "monthly_spending" in user_context:
            context_parts.append(f"æœˆåº¦æ”¯å‡º: Â¥{user_context['monthly_spending']:.2f}")

        if "subscriptions" in user_context:
            context_parts.append(f"è®¢é˜…æ€»æ•°: {len(user_context['subscriptions'])}")

        # è®¢é˜…è¯¦ç»†ä¿¡æ¯
        if "subscriptions" in user_context and user_context["subscriptions"]:
            context_parts.append("\nè®¢é˜…åˆ—è¡¨:")
            for sub in user_context["subscriptions"]:
                service = sub.get("service_name", "æœªçŸ¥æœåŠ¡")
                price = sub.get("price", 0)
                category = sub.get("category", "å…¶ä»–")
                status = sub.get("status", "active")
                context_parts.append(f"- {service}: Â¥{price}/æœˆ ({category}, {status})")

        # åˆ†ç±»ç»Ÿè®¡
        if "subscription_categories" in user_context:
            context_parts.append("\nåˆ†ç±»ç»Ÿè®¡:")
            for category, stats in user_context["subscription_categories"].items():
                context_parts.append(f"- {category}: {stats['count']}ä¸ªæœåŠ¡, Â¥{stats['spending']:.2f}/æœˆ")

        return "\n".join(context_parts) if context_parts else "æš‚æ— è®¢é˜…æ•°æ®"

    def _analyze_intent(self, user_message: str) -> str:
        """åˆ†æç”¨æˆ·æ„å›¾"""
        message_lower = user_message.lower()

        # å®šä¹‰æ„å›¾å…³é”®è¯
        intent_keywords = {
            "spending_query": ["èŠ±è´¹", "æ”¯å‡º", "é’±", "è´¹ç”¨", "æˆæœ¬", "å¤šå°‘"],
            "subscription_count": ["å¤šå°‘", "å‡ ä¸ª", "æ•°é‡", "è®¢é˜…"],
            "cancel_request": ["å–æ¶ˆ", "åœæ­¢", "åˆ é™¤", "é€€è®¢"],
            "optimization_advice": ["èŠ‚çœ", "çœé’±", "ä¼˜åŒ–", "å»ºè®®", "æ¨è"],
            "add_subscription": ["æ·»åŠ ", "æ–°å¢", "è®¢é˜…"],
            "category_analysis": ["åˆ†ç±»", "ç±»åˆ«", "åˆ†æ"],
            "trend_analysis": ["è¶‹åŠ¿", "å˜åŒ–", "é¢„æµ‹"],
            "general_help": ["å¸®åŠ©", "æ€ä¹ˆ", "å¦‚ä½•", "ä»€ä¹ˆ"]
        }

        # åŒ¹é…æ„å›¾
        for intent, keywords in intent_keywords.items():
            if any(keyword in message_lower for keyword in keywords):
                return intent

        return "general_query"

    def _calculate_confidence(self, response: Any, user_message: str) -> float:
        """è®¡ç®—å“åº”ç½®ä¿¡åº¦"""
        base_confidence = 0.8

        # æ ¹æ®æ¶ˆæ¯é•¿åº¦è°ƒæ•´ç½®ä¿¡åº¦
        message_length = len(user_message)
        if message_length < 10:
            base_confidence -= 0.1
        elif message_length > 50:
            base_confidence += 0.1

        # æ ¹æ®APIå“åº”è´¨é‡è°ƒæ•´
        if hasattr(response, 'choices') and response.choices:
            response_text = response.choices[0].message.content
            if len(response_text) > 100:
                base_confidence += 0.1
            if "Â¥" in response_text:  # åŒ…å«å…·ä½“æ•°æ®
                base_confidence += 0.05

        return min(0.95, max(0.5, base_confidence))

    def _get_fallback_response(self, user_message: str, user_context: Dict[str, Any]) -> str:
        """ç”Ÿæˆé™çº§å“åº”"""
        # å¯¼å…¥ç°æœ‰çš„æ¨¡æ‹Ÿå“åº”å‡½æ•°
        try:
            import sys
            from pathlib import Path
            project_root = Path(__file__).parent.parent.parent
            sys.path.insert(0, str(project_root))

            from ui.components.chat import get_ai_response_mock
            return get_ai_response_mock(user_message, user_context)
        except ImportError:
            return "æŠ±æ­‰ï¼ŒAIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ã€‚æ‚¨å¯ä»¥ç¨åé‡è¯•ï¼Œæˆ–è€…æŸ¥çœ‹æ•°æ®æ¦‚è§ˆé¡µé¢äº†è§£è®¢é˜…æƒ…å†µã€‚"

    async def generate_insights(self, user_context: Dict[str, Any]) -> List[Dict[str, str]]:
        """
        ç”Ÿæˆæ™ºèƒ½æ´å¯Ÿ

        Args:
            user_context: ç”¨æˆ·ä¸Šä¸‹æ–‡æ•°æ®

        Returns:
            æ´å¯Ÿåˆ—è¡¨
        """
        try:
            context_info = self._build_context_string(user_context)

            prompt = f"""åŸºäºä»¥ä¸‹ç”¨æˆ·æ•°æ®ï¼Œç”Ÿæˆ3-5ä¸ªæœ‰ä»·å€¼çš„è®¢é˜…ç®¡ç†æ´å¯Ÿï¼š

{context_info}

è¯·ä»¥JSONæ ¼å¼è¿”å›æ´å¯Ÿï¼Œæ¯ä¸ªæ´å¯ŸåŒ…å«ï¼š
- type: "info", "warning", "success" ä¸­çš„ä¸€ä¸ª
- icon: ç›¸å…³çš„emojiå›¾æ ‡
- title: æ´å¯Ÿæ ‡é¢˜
- content: è¯¦ç»†å†…å®¹

ç¤ºä¾‹æ ¼å¼ï¼š
[
  {{
    "type": "warning",
    "icon": "âš ï¸",
    "title": "æ”¯å‡ºè¾ƒé«˜æé†’",
    "content": "æ‚¨çš„æœˆåº¦è®¢é˜…æ”¯å‡ºè¾ƒé«˜ï¼Œå»ºè®®å®šæœŸè¯„ä¼°å„æœåŠ¡çš„ä½¿ç”¨é¢‘ç‡ã€‚"
  }}
]"""

            response = await openai.ChatCompletion.acreate(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªè®¢é˜…ç®¡ç†ä¸“å®¶ï¼Œæ“…é•¿æ•°æ®åˆ†æå’Œä¸ªæ€§åŒ–å»ºè®®ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=800,
                temperature=0.3
            )

            # å°è¯•è§£æJSONå“åº”
            insights_text = response.choices[0].message.content.strip()
            if insights_text.startswith("```json"):
                insights_text = insights_text[7:-3].strip()
            elif insights_text.startswith("```"):
                insights_text = insights_text[3:-3].strip()

            insights = json.loads(insights_text)
            return insights if isinstance(insights, list) else [insights]

        except Exception as e:
            # è¿”å›é»˜è®¤æ´å¯Ÿ
            return self._get_default_insights(user_context)

    def _get_default_insights(self, user_context: Dict[str, Any]) -> List[Dict[str, str]]:
        """ç”Ÿæˆé»˜è®¤æ´å¯Ÿ"""
        insights = []

        monthly_spending = user_context.get("monthly_spending", 0)
        subscriptions = user_context.get("subscriptions", [])
        categories = user_context.get("subscription_categories", {})

        # æ”¯å‡ºåˆ†æ
        if monthly_spending > 200:
            insights.append({
                "type": "warning",
                "icon": "âš ï¸",
                "title": "æ”¯å‡ºè¾ƒé«˜æé†’",
                "content": f"æ‚¨çš„æœˆåº¦è®¢é˜…æ”¯å‡ºä¸ºÂ¥{monthly_spending:.2f}ï¼Œå»ºè®®å®šæœŸè¯„ä¼°å„æœåŠ¡çš„ä½¿ç”¨é¢‘ç‡ã€‚"
            })

        # è®¢é˜…æ•°é‡åˆ†æ
        if len(subscriptions) > 5:
            insights.append({
                "type": "info",
                "icon": "ğŸ“±",
                "title": "è®¢é˜…æ•°é‡æé†’",
                "content": f"æ‚¨æœ‰{len(subscriptions)}ä¸ªæ´»è·ƒè®¢é˜…ï¼Œå¯ä»¥è€ƒè™‘æ•´åˆç›¸ä¼¼åŠŸèƒ½çš„æœåŠ¡ã€‚"
            })

        # å¨±ä¹æ”¯å‡ºåˆ†æ
        entertainment_cost = categories.get("entertainment", {}).get("spending", 0)
        if entertainment_cost > 50:
            insights.append({
                "type": "info",
                "icon": "ğŸ¬",
                "title": "å¨±ä¹æ”¯å‡ºåˆ†æ",
                "content": f"å¨±ä¹ç±»æ”¯å‡ºÂ¥{entertainment_cost:.2f}/æœˆï¼Œå¯ä»¥è€ƒè™‘é€‰æ‹©æ€§ä¿ç•™æœ€å¸¸ç”¨çš„æœåŠ¡ã€‚"
            })

        # å¦‚æœæ²¡æœ‰ç‰¹æ®Šæƒ…å†µï¼Œç»™å‡ºç§¯æåé¦ˆ
        if not insights:
            insights.append({
                "type": "success",
                "icon": "âœ…",
                "title": "è®¢é˜…ç»“æ„è‰¯å¥½",
                "content": "æ‚¨çš„è®¢é˜…ç®¡ç†æƒ…å†µå¾ˆä¸é”™ï¼Œç»§ç»­ä¿æŒå®šæœŸè¯„ä¼°çš„ä¹ æƒ¯ï¼"
            })

        return insights

# åˆ›å»ºå…¨å±€å®¢æˆ·ç«¯å®ä¾‹
_openai_client = None

def get_openai_client() -> Optional[OpenAIClient]:
    """è·å–OpenAIå®¢æˆ·ç«¯å®ä¾‹"""
    global _openai_client

    if _openai_client is None:
        try:
            _openai_client = OpenAIClient()
        except ValueError:
            # APIå¯†é’¥æœªé…ç½®ï¼Œè¿”å›None
            return None

    return _openai_client

def is_openai_available() -> bool:
    """æ£€æŸ¥OpenAI APIæ˜¯å¦å¯ç”¨"""
    return get_openai_client() is not None